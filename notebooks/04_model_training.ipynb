{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9920ebe9",
   "metadata": {},
   "source": [
    "this is going to be the notebook for our model training with step by step explanation of what we are trying to achieve, and building on top of the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d8b5d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45222, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = pd.read_csv('../data/adult_clean.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c732381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45222, 14)\n",
      "['age', 'workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'class']\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['Unnamed: 0', 'fnlwgt'], errors='ignore')\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())\n",
    "\n",
    "df.to_csv('../data/adult_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9736d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (45222, 13)\n",
      "Target: (45222,)\n",
      "Target distribution:\n",
      "class\n",
      "<=50K    0.752156\n",
      ">50K     0.247844\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "print(f\"Features: {X.shape}\")\n",
    "print(f\"Target: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30f055ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (36177, 13), (36177,) rows\n",
      "Test set: (9045, 13), (9045,) rows\n",
      "Training target distribution:\n",
      "class\n",
      "<=50K    0.752163\n",
      ">50K     0.247837\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape} rows\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape} rows\")\n",
    "print(f\"Training target distribution:\\n{y_train.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b1fd935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
      "Numeric: ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Categorical: {categorical_cols}\")\n",
    "print(f\"Numeric: {numeric_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1e0373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9808da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9438c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaffb288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 9045\n",
      "Sample Predictions: ['<=50K' '<=50K' '<=50K' '>50K' '<=50K' '<=50K' '<=50K' '<=50K' '<=50K'\n",
      " '<=50K']\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Predictions: {len(y_pred)}\")\n",
    "print(f\"Sample Predictions: {y_pred[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85befc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
